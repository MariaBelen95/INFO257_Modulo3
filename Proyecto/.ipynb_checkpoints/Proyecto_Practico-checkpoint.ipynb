{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto práctico\n",
    "\n",
    "## Unidad 3 - Aprendizaje supervisado\n",
    "\n",
    "El proyecto práctico consiste en abordar un problema de clasificación de documentos textuales. Tenemos a nuestra disposición un dataset de noticias de prensa en español publicada por el medio \"CNN Chile\".\n",
    "\n",
    "Las noticias están divididas en 7 categorías temáticas: *'pais','deportes','tendencias','tecnologias','cultura','economia','mundo'*\n",
    "\n",
    "El proyecto se divide en dos partes:\n",
    "\n",
    "- Utilizar al menos 3 estrategías para entrenar modelos de clasificación capaces de clasificar las noticias según su categoría temática.\n",
    "\n",
    "- Explorar cuáles son las características que permiten explicar las decisiones de su modelo.\n",
    "\n",
    "## 0 Evaluación\n",
    "\n",
    "El proyecto se realiza de forma individual. Se entrega a más tardar el **lunes 30 de noviembre** en su repositorio GitHub.\n",
    "\n",
    "**Pauta de evaluación:**\n",
    "\n",
    "Competencia 1: Aplicar un protocolo de aprendizaje supervisado para resolver un problema clasificación estandar, utilizando un entorno de programación en Python\n",
    "\n",
    "- < 2 : El protocolo de aprendizaje supervisado utilizado es incompleto y/o presenta errores importantes\n",
    "- 2 a 3.9 : El protocolo de aprendizaje supervisado utilizado es incompleto o presenta un error importante\n",
    "- 4 a 5.5 : El protocolo de aprendizaje es completo, no tiene error, pero las estrategias utilizadas son relativamente simples y el rendimiento de los modelos es perfectible.\n",
    "- 5.6 a 7.0 : El protocolo de aprendizaje es completo, no tiene error y al menos una de las estrategias utilizadas a necesitado un trabajado más avanzado y/o permite obtener un mejor rendimiento.\n",
    "\n",
    "Competencia 2: Explicar el rendimiento de un modelo de clasificación aplicando un protocolo de evaluación Precision/Recall/F-Score\n",
    "\n",
    "- < 2 : El trabajo no presenta explicaciones del rendimiento de los modelos de clasificación\n",
    "- 2 a 3.9 : El trabajo presenta algunas explicaciones pero tienen errores.\n",
    "- 4 a 5.5 : El trabajo presenta explicaciones correctas del rendimiento de los modelos\n",
    "- 5.6 a 7 : El trabajo presenta explicaciones correctas del rendimiento de los modelos y además presenta un método para explicar las decisiones/errores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>media_outlet</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chile</td>\n",
       "      <td>cnnchile</td>\n",
       "      <td>https://www.cnnchile.com/pais/pdta-del-colegio...</td>\n",
       "      <td>Pdta. del Colegio de Matronas explicó los ries...</td>\n",
       "      <td>La Federación de Estudiantes de la Universidad...</td>\n",
       "      <td>2018-03-29 00:00:00.000000</td>\n",
       "      <td>pais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chile</td>\n",
       "      <td>cnnchile</td>\n",
       "      <td>https://www.cnnchile.com/pais/defensoria-ninez...</td>\n",
       "      <td>Defensoría de la Niñez pide al Estado velar po...</td>\n",
       "      <td>La Defensoría de la Niñez emitió este domingo ...</td>\n",
       "      <td>2020-08-02 00:00:00.000000</td>\n",
       "      <td>pais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chile</td>\n",
       "      <td>cnnchile</td>\n",
       "      <td>https://www.cnnchile.com/pais/cuanto-les-pagar...</td>\n",
       "      <td>¿Cuánto les pagarán a los vocales de mesa?</td>\n",
       "      <td>El monto del bono es de dos tercios de Unidad ...</td>\n",
       "      <td>2016-10-20 00:00:00.000000</td>\n",
       "      <td>pais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chile</td>\n",
       "      <td>cnnchile</td>\n",
       "      <td>https://www.cnnchile.com/pais/sobrino-de-aleja...</td>\n",
       "      <td>Sobrino de Alejandro Navarro intenta “funar” e...</td>\n",
       "      <td>Una nueva polémica tiene esta carrera presiden...</td>\n",
       "      <td>2017-11-13 00:00:00.000000</td>\n",
       "      <td>pais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chile</td>\n",
       "      <td>cnnchile</td>\n",
       "      <td>https://www.cnnchile.com/pais/analisis-sobre-e...</td>\n",
       "      <td>Análisis sobre el aumento de impuestos para al...</td>\n",
       "      <td>Especialistas recomiendan no consumir más de 2...</td>\n",
       "      <td>2014-05-05 00:00:00.000000</td>\n",
       "      <td>pais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>chile</td>\n",
       "      <td>cnnchile</td>\n",
       "      <td>https://www.cnnchile.com/tecnologias/playstati...</td>\n",
       "      <td>PlayStation 5 vs Xbox Series X: Mira la compar...</td>\n",
       "      <td>Las compañías ya han revelado muchos detalles ...</td>\n",
       "      <td>2020-09-18 00:00:00.000000</td>\n",
       "      <td>tecnologias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6996</th>\n",
       "      <td>chile</td>\n",
       "      <td>cnnchile</td>\n",
       "      <td>https://www.cnnchile.com/tecnologias/android-l...</td>\n",
       "      <td>Android le dará “una paliza” a Windows en 2013</td>\n",
       "      <td>Se proyecta que tras un virtual empate en 2012...</td>\n",
       "      <td>2013-04-04 00:00:00.000000</td>\n",
       "      <td>tecnologias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>chile</td>\n",
       "      <td>cnnchile</td>\n",
       "      <td>https://www.cnnchile.com/tecnologias/regalos-t...</td>\n",
       "      <td>Regalos tecnológicos marcaron pauta en Navidad</td>\n",
       "      <td>Tablets y smartphones fueron los regalos tecno...</td>\n",
       "      <td>2012-12-26 00:00:00.000000</td>\n",
       "      <td>tecnologias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6998</th>\n",
       "      <td>chile</td>\n",
       "      <td>cnnchile</td>\n",
       "      <td>https://www.cnnchile.com/tecnologias/jugar-con...</td>\n",
       "      <td>Jugar con Fox en Starlink vale totalmente la p...</td>\n",
       "      <td>Crecí jugando clásicos de naves como Terminal ...</td>\n",
       "      <td>2018-10-30 00:00:00.000000</td>\n",
       "      <td>tecnologias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999</th>\n",
       "      <td>chile</td>\n",
       "      <td>cnnchile</td>\n",
       "      <td>https://www.cnnchile.com/tecnologias/konami-la...</td>\n",
       "      <td>Konami lanza PES 2018 de forma gratuita para i...</td>\n",
       "      <td>Konami Digital Entertainment ha anunciado que ...</td>\n",
       "      <td>2017-11-10 00:00:00.000000</td>\n",
       "      <td>tecnologias</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     country media_outlet                                                url  \\\n",
       "0      chile     cnnchile  https://www.cnnchile.com/pais/pdta-del-colegio...   \n",
       "1      chile     cnnchile  https://www.cnnchile.com/pais/defensoria-ninez...   \n",
       "2      chile     cnnchile  https://www.cnnchile.com/pais/cuanto-les-pagar...   \n",
       "3      chile     cnnchile  https://www.cnnchile.com/pais/sobrino-de-aleja...   \n",
       "4      chile     cnnchile  https://www.cnnchile.com/pais/analisis-sobre-e...   \n",
       "...      ...          ...                                                ...   \n",
       "6995   chile     cnnchile  https://www.cnnchile.com/tecnologias/playstati...   \n",
       "6996   chile     cnnchile  https://www.cnnchile.com/tecnologias/android-l...   \n",
       "6997   chile     cnnchile  https://www.cnnchile.com/tecnologias/regalos-t...   \n",
       "6998   chile     cnnchile  https://www.cnnchile.com/tecnologias/jugar-con...   \n",
       "6999   chile     cnnchile  https://www.cnnchile.com/tecnologias/konami-la...   \n",
       "\n",
       "                                                  title  \\\n",
       "0     Pdta. del Colegio de Matronas explicó los ries...   \n",
       "1     Defensoría de la Niñez pide al Estado velar po...   \n",
       "2            ¿Cuánto les pagarán a los vocales de mesa?   \n",
       "3     Sobrino de Alejandro Navarro intenta “funar” e...   \n",
       "4     Análisis sobre el aumento de impuestos para al...   \n",
       "...                                                 ...   \n",
       "6995  PlayStation 5 vs Xbox Series X: Mira la compar...   \n",
       "6996     Android le dará “una paliza” a Windows en 2013   \n",
       "6997     Regalos tecnológicos marcaron pauta en Navidad   \n",
       "6998  Jugar con Fox en Starlink vale totalmente la p...   \n",
       "6999  Konami lanza PES 2018 de forma gratuita para i...   \n",
       "\n",
       "                                                   text  \\\n",
       "0     La Federación de Estudiantes de la Universidad...   \n",
       "1     La Defensoría de la Niñez emitió este domingo ...   \n",
       "2     El monto del bono es de dos tercios de Unidad ...   \n",
       "3     Una nueva polémica tiene esta carrera presiden...   \n",
       "4     Especialistas recomiendan no consumir más de 2...   \n",
       "...                                                 ...   \n",
       "6995  Las compañías ya han revelado muchos detalles ...   \n",
       "6996  Se proyecta que tras un virtual empate en 2012...   \n",
       "6997  Tablets y smartphones fueron los regalos tecno...   \n",
       "6998  Crecí jugando clásicos de naves como Terminal ...   \n",
       "6999  Konami Digital Entertainment ha anunciado que ...   \n",
       "\n",
       "                            date     category  \n",
       "0     2018-03-29 00:00:00.000000         pais  \n",
       "1     2020-08-02 00:00:00.000000         pais  \n",
       "2     2016-10-20 00:00:00.000000         pais  \n",
       "3     2017-11-13 00:00:00.000000         pais  \n",
       "4     2014-05-05 00:00:00.000000         pais  \n",
       "...                          ...          ...  \n",
       "6995  2020-09-18 00:00:00.000000  tecnologias  \n",
       "6996  2013-04-04 00:00:00.000000  tecnologias  \n",
       "6997  2012-12-26 00:00:00.000000  tecnologias  \n",
       "6998  2018-10-30 00:00:00.000000  tecnologias  \n",
       "6999  2017-11-10 00:00:00.000000  tecnologias  \n",
       "\n",
       "[7000 rows x 7 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('cnnchile_7000.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>count(*)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tendencias</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tecnologias</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pais</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mundo</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>economia</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>deportes</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cultura</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      category  count(*)\n",
       "0   tendencias      1000\n",
       "1  tecnologias      1000\n",
       "2         pais      1000\n",
       "3        mundo      1000\n",
       "4     economia      1000\n",
       "5     deportes      1000\n",
       "6      cultura      1000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandasql import sqldf\n",
    "\n",
    "q=\"\"\"SELECT category, count(*) FROM df GROUP BY category ORDER BY count(*) DESC;\"\"\"\n",
    "result=sqldf(q)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='category', ylabel='count'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sb\n",
    "\n",
    "sb.countplot(x='category',data=df, palette='hls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country         0\n",
       "media_outlet    0\n",
       "url             0\n",
       "title           1\n",
       "text            0\n",
       "date            0\n",
       "category        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"es\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Bag of Words + tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la primera implementación de una solución, se escogió el método de regresión lógistica, **Bag of Words + tf-idf**, esto dado las características del problema (clasificación de texto por categoría)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(text):\n",
    "    \n",
    "    mytokens = nlp(text)\n",
    "\n",
    "    #Guardamos las palabras como características si corresponden a ciertas categorias gramaticales\n",
    "    mytokens = [ word for word in mytokens if word.pos_ in [\"NOUN\", \"ADJ\", \"VERB\"] ]\n",
    "    \n",
    "    #Transformamos las palabras en minusculas\n",
    "    mytokens = [ word.lemma_.lower().strip() for word in mytokens ]\n",
    "\n",
    "    # return preprocessed list of tokens\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printMostImportantFeatures(vectorizer, model, N):\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    coefs_with_fns = sorted(zip(model.coef_[0], feature_names))\n",
    "    topClass1 = coefs_with_fns[:N]\n",
    "    topClass2 = coefs_with_fns[:-(N + 1):-1]\n",
    "    print(\"Class 1 best: \")\n",
    "    for feat in topClass1:\n",
    "        print(feat)\n",
    "    print(\"Class 2 best: \")\n",
    "    for feat in topClass2:\n",
    "        print(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vector = TfidfVectorizer(tokenizer = feature_extraction, min_df=0., max_df=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se busca identificar la categoría de la noticia mediante el texto de esta, se separa la muestra en una submuestra a utilizar para el entrenamiento y otra para testear la máquina, cada una con sus respectivas etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['text'] \n",
    "ylabels = df['category']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La máquina es entrenada usando Pipeline y LogisticRegresion de la librería sklearn.\n",
    "El método LogisticRegresion de sklearn, funciona para los casos multiclass como este, usando un algoritmo OvR (One vs Rest) o bien usando la función de perdida Cross-Entropy. Esto se puede ajustar cambiando el valor del parametro multi_class en el método LogisticRegresion, el valor por defecto es 'auto'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizing',\n",
       "                 TfidfVectorizer(min_df=0.0,\n",
       "                                 tokenizer=<function feature_extraction at 0x121980160>)),\n",
       "                ('learning', LogisticRegression())])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_2 = LogisticRegression()\n",
    "\n",
    "pipe = Pipeline([('vectorizing', tfidf_vector),\n",
    "                 ('learning', model_2)])\n",
    "\n",
    "# model generation\n",
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Evaluación del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['deportes' 'economia' 'deportes' ... 'cultura' 'tecnologias' 'deportes']\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "predicted = pipe.predict(X_test)\n",
    "\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.7568571428571429\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy\n",
    "print(\"Logistic Regression Accuracy:\",metrics.accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este modelo nos da una precisión aproximada del 76% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[448   1   1  15   9   6  22]\n",
      " [  5 429  10  10  12   3  30]\n",
      " [  0  11 410  13  54  15   4]\n",
      " [ 16  16  30 359  38  12  25]\n",
      " [  3  12  47  58 341  12  14]\n",
      " [ 12  23  25   9  22 352  58]\n",
      " [ 57  27  14  19  20  61 310]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     cultura       0.83      0.89      0.86       502\n",
      "    deportes       0.83      0.86      0.84       499\n",
      "    economia       0.76      0.81      0.79       507\n",
      "       mundo       0.74      0.72      0.73       496\n",
      "        pais       0.69      0.70      0.69       487\n",
      " tecnologias       0.76      0.70      0.73       501\n",
      "  tendencias       0.67      0.61      0.64       508\n",
      "\n",
      "    accuracy                           0.76      3500\n",
      "   macro avg       0.75      0.76      0.75      3500\n",
      "weighted avg       0.75      0.76      0.76      3500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Matriz de confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix = confusion_matrix(y_test, predicted)\n",
    "print(confusion_matrix)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomando en cuenta que el índice de precisión se refiere a la proporción de true positives dentro de todos los true and false positives, el recall es proporción de true positives dentro de true positives y false negatives, mientras que el f1-score es la media entre precisión y recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo muestra **menor nivel de precisión** al predecir noticias de la categoría **tendencias** con un **0.67** y un **mayor nivel** al predecir noticias de **cultura y deportes** con **0.83**, mientras que presenta **mayor recall** en la predicción de noticias de **cultura** con **0.89** y **menor en tendencias** con **0.61**. En promedio, el modelo es mejor al predecir noticias de cultura y deportes con un f1-score de 0.87 y 0.88 respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1 best: \n",
      "(-1.4069665268761737, 'adjuntar')\n",
      "(-1.1851709376967883, 'presidente')\n",
      "(-1.1492887069118471, \"'\")\n",
      "(-1.1348895822055949, '=')\n",
      "(-1.0893814293271085, 'empresa')\n",
      "(-1.0847154186733752, 'video')\n",
      "(-1.0287825310075909, 'utilizar')\n",
      "(-0.9180478682013332, 'detalle')\n",
      "(-0.8498893891160231, 'jugador')\n",
      "(-0.8385596377204037, 'ministro')\n",
      "(-0.8156701298814562, 'jugar')\n",
      "(-0.8094633478004927, 'lanoticiacnn')\n",
      "(-0.7834793146527861, 'aumentar')\n",
      "(-0.7170742111339268, 'informar')\n",
      "(-0.7080939598845304, 'revisar')\n",
      "(-0.7021631833551993, 'usuario')\n",
      "(-0.6720727122296414, 'blocar')\n",
      "(-0.6540487229595922, 'producto')\n",
      "(-0.6501418357966208, 'fútbol')\n",
      "(-0.6500703081412149, 'mandatario')\n",
      "Class 2 best: \n",
      "(3.512817493258223, 'película')\n",
      "(3.183905100170615, 'artista')\n",
      "(2.6914621746886054, 'seriar')\n",
      "(2.5639322665237203, 'canción')\n",
      "(2.4860217636791075, 'músico')\n",
      "(2.350782739912899, 'banda')\n",
      "(2.2990296425925747, 'estrenar')\n",
      "(2.2669341329560795, 'ser')\n",
      "(2.1206633414984264, 'cantante')\n",
      "(2.0686290171835693, 'historia')\n",
      "(2.023874197375002, 'temporada')\n",
      "(1.997674328155343, 'festival')\n",
      "(1.9652748121748613, 'actriz')\n",
      "(1.9441655619570202, 'personaje')\n",
      "(1.913491549912372, 'disco')\n",
      "(1.8715055146989006, 'producción')\n",
      "(1.8093426601723712, 'cine')\n",
      "(1.7618774774135082, 'concertar')\n",
      "(1.713071751855348, 'teatro')\n",
      "(1.7127437932719927, 'obrar')\n"
     ]
    }
   ],
   "source": [
    "printMostImportantFeatures(tfidf_vector, model_2, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Naïve Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Entrenamiento MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "nb = MultinomialNB()\n",
    "\n",
    "model_nb = Pipeline([('vectorizing', tfidf_vector),\n",
    "                 ('learning', nb)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizing',\n",
       "                 TfidfVectorizer(min_df=0.0,\n",
       "                                 tokenizer=<function feature_extraction at 0x126d8a940>)),\n",
       "                ('learning', MultinomialNB())])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Evaluación del Modelo MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model_nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes Accuracy: 0.7568571428571429\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "# Model Accuracy\n",
    "print(\"Naïve Bayes Accuracy:\",metrics.accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[478   0   2  16   6   4   4]\n",
      " [ 21 418  17  16   9   7  20]\n",
      " [  3  14 429   6  30  21   2]\n",
      " [ 23  12  32 367  38  20  11]\n",
      " [ 13  13  59  50 344   4  15]\n",
      " [ 29  21  32   7  15 352  53]\n",
      " [ 81  15   9  18  15  68 261]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     cultura       0.74      0.94      0.83       510\n",
      "    deportes       0.85      0.82      0.84       508\n",
      "    economia       0.74      0.85      0.79       505\n",
      "       mundo       0.76      0.73      0.75       503\n",
      "        pais       0.75      0.69      0.72       498\n",
      " tecnologias       0.74      0.69      0.71       509\n",
      "  tendencias       0.71      0.56      0.63       467\n",
      "\n",
      "    accuracy                           0.76      3500\n",
      "   macro avg       0.76      0.75      0.75      3500\n",
      "weighted avg       0.76      0.76      0.75      3500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(y_test, predicted)\n",
    "\n",
    "print(confusion_matrix)\n",
    "\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con este modelo obtenemos un **accuracy de 0.76**, donde la categoría con **mayor índice de precision** al predecir es **deportes** con **0.85** y el con **menor precision es tendencias** con **0.71**. La categoría con **mayor recall es cultura** con **0.94** y la de **menor recall es tendencias** con **0.56**. Promediando precision y recall obtenemos que los **mejores f1-scores** son en **deportes, cultura y economía**, cada uno con **0.84, 0.83 y 0.79** respectivamente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación encontramos las 10 palabras con mayor probabilidad logarítmica para cada categoría según el modelo Naïve Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_salient_words(nb_clf, vect, class_ind):\n",
    "    \"\"\"Return salient words for given class\n",
    "    Parameters\n",
    "    ----------\n",
    "    nb_clf : a Naive Bayes classifier (e.g. MultinomialNB, BernoulliNB)\n",
    "    vect : CountVectorizer\n",
    "    class_ind : int\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        a sorted list of (word, log prob) sorted by log probability in descending order.\n",
    "    \"\"\"\n",
    "\n",
    "    words = vect.get_feature_names()\n",
    "    zipped = list(zip(words, nb_clf.feature_log_prob_[class_ind]))\n",
    "    sorted_zip = sorted(zipped, key=lambda t: t[1], reverse=True)\n",
    "\n",
    "    return sorted_zip\n",
    "\n",
    "cul_salient_top = get_salient_words(nb, tfidf_vector, 0)[:10]\n",
    "dep_salient_top = get_salient_words(nb, tfidf_vector, 1)[:10]\n",
    "eco_salient_top = get_salient_words(nb, tfidf_vector, 2)[:10]\n",
    "mun_salient_top = get_salient_words(nb, tfidf_vector, 3)[:10]\n",
    "pai_salient_top = get_salient_words(nb, tfidf_vector, 4)[:10]\n",
    "tec_salient_top = get_salient_words(nb, tfidf_vector, 5)[:10]\n",
    "ten_salient_top = get_salient_words(nb, tfidf_vector, 6)[:10]\n",
    "\n",
    "print('Cultura:')\n",
    "print(cul_salient_top)\n",
    "print('Deporte:')\n",
    "print(dep_salient_top)\n",
    "print('Economía:')\n",
    "print(eco_salient_top)\n",
    "print('Mundo:')\n",
    "print(mun_salient_top)\n",
    "print('País:')\n",
    "print(pai_salient_top)\n",
    "print('Tecnología:')\n",
    "print(tec_salient_top)\n",
    "print('Tendencia:')\n",
    "print(ten_salient_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Neuronal Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Preparación de los Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como primer paso para el diseño de nuestro modelo, debemos separar el dataset en tres muestras de este, una para entrenar el modelo, otro para validación y el último para testearlo. Se escogió dividirlo con una razón de 0.7 para la muestra de entrenamiento y 0.15 tanto para validación como para testeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import RandomState\n",
    "\n",
    "rng = RandomState()\n",
    "\n",
    "train = df.sample(frac=0.7, random_state=rng)\n",
    "aux = df.loc[~df.index.isin(train.index)]\n",
    "valid = aux.sample(frac=0.5, random_state=rng)\n",
    "test = aux.loc[~aux.index.isin(valid.index)]\n",
    "\n",
    "train.to_csv('train_data.csv')\n",
    "valid.to_csv('valid_data.csv')\n",
    "test.to_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='category', ylabel='count'>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sb.countplot(x='category',data=train, palette='hls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como la distribución de los datos por categoría en la muestra de entrenamiento es pareja, se acepta la subdivisión actual para continuar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import spacy\n",
    "import random\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "from torchtext import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "TEXT = data.Field(tokenize = 'spacy')\n",
    "LABEL = data.LabelField()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [(None, None), (None,None), (None,None), (None,None), (None,None), ('text', TEXT), (None,None), ('category', LABEL)]\n",
    "\n",
    "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
    "                                        path = '.',\n",
    "                                        train = 'train_data.csv',\n",
    "                                        validation= 'valid_data.csv',\n",
    "                                        test = 'test_data.csv',\n",
    "                                        format = 'csv',\n",
    "                                        fields = fields,\n",
    "                                        skip_header = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['Desde', 'el', '26', 'de', 'Octubre', 'al', '\\xa0', '1', 'de', 'Noviembre', ',', 'se', 'llevará', 'a', 'cabo', 'el', 'evento', 'de', 'Halloween', 'donde', 'habrá', 'mayor', 'presencia', 'noctura', 'de', 'pokémon', 'como', '\\xa0', 'Gastly', ',', 'Hunter', ',', 'Gengar', ',', '\\xa0', 'Zubat', ',', 'Golbat', ',', 'Drowzee', 'e', 'Hypno', '.', 'Además', ',', 'se', 'duplicarán', 'la', 'obtención', 'de', 'caramelos', 'al', 'momento', 'de', 'eclosionar', 'un', 'huevo', ',', 'atrapar', 'un', 'pokémon', 'o', 'transferirlo', 'a', 'la', 'granja', '.', 'También', 'se', 'conseguirá', 'más', 'caramelos', 'con', 'el', 'acompañante', ',', 'ya', 'que', 'la', 'medición', 'del', 'kilometraje', 'será', '4', 'veces', 'mejor', '.', 'Este', 'será', 'un', 'hito', 'en', 'Pokémon', 'GO', 'para', 'probar', 'el', 'primer', 'evento', 'desde', 'el', 'lanzamiento', 'del', 'juego', '.'], 'category': 'tecnologias'}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 20\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device,\n",
    "    sort_key=lambda x:len(x.category),\n",
    "    sort_within_batch=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se usó un Batch Size de 20 con la intención de que el tiempo de entrenamiento por batch no fuera demasiado alto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Arquitectura CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se cargan vectores de palabras en español"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 25000\n",
    "\n",
    "vec = torchtext.vocab.Vectors('glove-sbwc.i25.vec', cache='./Downloads/')\n",
    "\n",
    "TEXT.build_vocab(train_data, \n",
    "                 max_size = MAX_VOCAB_SIZE, \n",
    "                 vectors = vec, \n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(None, {'cultura': 0, 'deportes': 1, 'mundo': 2, 'economia': 3, 'tecnologias': 4, 'tendencias': 5, 'pais': 6})\n"
     ]
    }
   ],
   "source": [
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo usa valores númericos para cada categoría, los cuales son asignados de forma automática y corresponden a cada uno de la siguiente forma:\n",
    "\n",
    "- 0: Cultura\n",
    "- 1: Deportes\n",
    "- 2: Mundo\n",
    "- 3: Economía\n",
    "- 4: Tecnologías\n",
    "- 5: Tendencias\n",
    "- 6: País"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size = (fs, embedding_dim)) \n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        #text = [sent len, batch size]\n",
    "        \n",
    "        text = text.permute(1, 0)\n",
    "                \n",
    "        #text = [batch size, sent len]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        \n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        \n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "            \n",
    "        #conv_n = [batch size, n_filters, sent len - filter_sizes[n]]\n",
    "        \n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        \n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "            \n",
    "        return self.fc(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 300\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [3,4,5]\n",
    "OUTPUT_DIM = len(LABEL.vocab)\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de múltiples pruebas con el número de filtros y los tamaños, se opta por usar 100 filtros de tamaños 3, 4 y 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "\n",
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Funciones de optimización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.text)\n",
    "        \n",
    "        loss = criterion(predictions, batch.category)\n",
    "        \n",
    "        acc = categorical_accuracy(predictions, batch.category)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Funciones de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
    "    correct = max_preds.squeeze(1).eq(y)\n",
    "    return correct.sum() / torch.FloatTensor([y.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.text)\n",
    "            \n",
    "            loss = criterion(predictions, batch.category)\n",
    "            \n",
    "            acc = categorical_accuracy(predictions, batch.category)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 16m 27s\n",
      "\tTrain Loss: 1.341 | Train Acc: 49.37%\n",
      "\t Val. Loss: 0.860 |  Val. Acc: 68.68%\n",
      "Epoch: 02 | Epoch Time: 14m 20s\n",
      "\tTrain Loss: 0.784 | Train Acc: 72.45%\n",
      "\t Val. Loss: 0.774 |  Val. Acc: 71.70%\n",
      "Epoch: 03 | Epoch Time: 14m 23s\n",
      "\tTrain Loss: 0.551 | Train Acc: 81.65%\n",
      "\t Val. Loss: 0.728 |  Val. Acc: 75.09%\n",
      "Epoch: 04 | Epoch Time: 14m 6s\n",
      "\tTrain Loss: 0.348 | Train Acc: 88.71%\n",
      "\t Val. Loss: 0.748 |  Val. Acc: 74.91%\n",
      "Epoch: 05 | Epoch Time: 14m 19s\n",
      "\tTrain Loss: 0.228 | Train Acc: 92.88%\n",
      "\t Val. Loss: 0.726 |  Val. Acc: 75.28%\n",
      "Epoch: 06 | Epoch Time: 15m 34s\n",
      "\tTrain Loss: 0.158 | Train Acc: 95.29%\n",
      "\t Val. Loss: 0.776 |  Val. Acc: 76.04%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 6\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), './category-model-CNN'+'_ep'+str(epoch+1)+'.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a la condición establecida que dice que solo se guardan los modelos donde el valor de su valid_loss sea menor al best_valid_loss, solo se guardan los modelos 1, 2, 3 y 5. De estos, el mejor es el quinto y es a este al que evaluaremos a continuación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "best_model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "best_model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "best_model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = './category-model-CNN'+'_ep'+str(5)+'.pt'\n",
    "best_model.load_state_dict(torch.load(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediction_test = []\n",
    "labels_test=[]\n",
    "for batch in test_iterator:\n",
    "    labels_test.append(batch.category.cpu().detach().numpy())\n",
    "    predictions = best_model(batch.text.cpu()).squeeze(1)\n",
    "    rounded_preds = predictions.argmax(dim = 1, keepdim = True)\n",
    "    prediction_test.append(rounded_preds.detach().numpy())\n",
    "    \n",
    "y_true = np.concatenate(labels_test)\n",
    "y_pred = np.concatenate(prediction_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3],\n",
       "       [6],\n",
       "       [6],\n",
       "       ...,\n",
       "       [1],\n",
       "       [4],\n",
       "       [4]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([6, 6, 6, ..., 4, 4, 4])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(y_pred,y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 6, 6, ..., 1, 4, 4])"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 99,   0,   5,   0,   6,  19,   6],\n",
       "       [  0, 117,   5,   7,   1,   3,  10],\n",
       "       [  3,   1, 104,  10,   4,   3,  28],\n",
       "       [  0,   3,   4, 106,   7,   2,  27],\n",
       "       [  2,   6,   3,   7, 113,  17,   8],\n",
       "       [ 11,   3,   8,   5,  25, 105,   9],\n",
       "       [  2,   3,  18,   9,   2,   1, 113]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.73      0.79       135\n",
      "           1       0.88      0.82      0.85       143\n",
      "           2       0.71      0.68      0.69       153\n",
      "           3       0.74      0.71      0.72       149\n",
      "           4       0.72      0.72      0.72       156\n",
      "           5       0.70      0.63      0.66       166\n",
      "           6       0.56      0.76      0.65       148\n",
      "\n",
      "    accuracy                           0.72      1050\n",
      "   macro avg       0.74      0.72      0.73      1050\n",
      "weighted avg       0.73      0.72      0.72      1050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
    "\n",
    "cm = confusion_matrix(\n",
    "    y_true, y_pred[:,0])\n",
    "display(cm)\n",
    "\n",
    "print(classification_report(y_true, y_pred[:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como primer método de evaluación usamos la matriz de confusión y el reporte de clasificación, este nos dice que el modelo tiene un **0.88 de precision** al predecir noticias de la clase 1 (**Deportes**), y tan solo un **0.56 de precision** al predecir noticias de la clase 6 (**País**). En cuanto al **recall**, tenemos **0.82** para la clase 1 (**Deportes**), mientras que el **menor recall** lo tenemos en la clase 5 (**País**) con un **0.63**. Los **mejores f1-score** son para las clases 1 y 0 (**Deportes y Cultura**) con **0.85 y 0.79**, mientras que **los más bajos** son para las clases 6 y 5 (**País y Tendencias**) con **0.65 y 0.66**.\n",
    "Además este método de evaluación nos arroja un **accuracy** del **0.72**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.761 | Test Acc: 74.34%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('category-model-CNN'+'_ep'+str(5)+'.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El segundo método de evaluación nos entrega el cálculo de la función de pérdida y el accuracy en el testeo usando el método evaluate() que se encuentra definido más arriba. Para la función de pérdida se usa CrossEntropy, mientras que el accuracy está definido como la precisión categórica, la cual nos da el accuracy por batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este trabajo, el mejor modelo en cuanto a accuracy terminó siendo el de Naïve Bayes con un 75%, aún así, el modelo de redes neuronales podría seguir siendo mejorado cambiando parámetros como el batch size, el número y tamaños de filtros, número de epochs, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "204px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
